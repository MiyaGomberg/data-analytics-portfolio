{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Z2ld_oYpXTlS",
        "HhyI1UgEcxOC"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MiyaGomberg/data-analytics-portfolio/blob/main/Milestone_Project_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lDZZErLuVot"
      },
      "source": [
        "#Milestone Project 3\n",
        "\n",
        "##Part 1: Planning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnXcVBJtuTPC"
      },
      "source": [
        "### Task 1: Choose a Research Question\n",
        "\n",
        "For this task, we're going to focus on formulating a research question with a compelling, real-world application that can be answered using a machine learning model. There is no specific area or topic that you're required to investigate.  In fact, it's usually more interesting if you're exploring your own personal interests or answering a question related to the industry where you will direct your job search."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZ6b1PQlvbOO"
      },
      "source": [
        "**The most important rule of research questions is to actually have one.** Many, many projects suffer because the learner begins with a vague, general sense of direction but doesn’t have a clear, specific question to answer.  For example, you might wish to complete your Milestone 3 project about shopping habits at a particular online retailer, but the data you use and the ML model you develop will depend on your specific research question.  \n",
        "\n",
        "For example, you’ll need different methods to answer the question “Are customers who see a new version of the store website more likely to make a purchase?” than to answer the question, “What products do customers often purchase in the same order?”"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eoj8fOkfvgDc"
      },
      "source": [
        "**The second most important rule of research questions is not to get in over your head.**  If you are really interested in your topic, you will probably have lots and lots of research questions that you are tempted to answer with this project.  Do not do it!  For this project, you will answer one (and only one) specific, well-defined question.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHMfV_zbvlwM"
      },
      "source": [
        "Research is not a mechanical process and often doesn’t proceed in a straight line, but it's almost always best to spend time at the start of your project developing and refining a core question that will motivate your study: it makes every aspect of the research process easier.\n",
        "\n",
        "\n",
        "**Although you may need to try a lot of things on your way to answering your research question, please remove any code that is not part of your finished project before submitting.**\n",
        "\n",
        "**This notebook should be able to run from start to finish without error.** \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjqNOJ6NvrDS"
      },
      "source": [
        "**Step 1** \n",
        "\n",
        "Brainstorm three industries or topics that you most interested in exploring for this project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tqyA-_QwShM"
      },
      "source": [
        "**Step 1 Answer**\n",
        "\n",
        "1. Science\n",
        "2. Humanitarian/aids\n",
        "3. Health"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSFgF22pwbxx"
      },
      "source": [
        "**Step 2** \n",
        "\n",
        "Pick the industry or topic from Step 1 that interests you the most.  Brainstorm three potential research questions that you could answer for this project.  **Right now, the question will be fairly broad.  You will refine your research question once you select your data set.**  Each potential research question should have the following qualities:\n",
        "\n",
        "*   It's a question, not a statement.\n",
        "*   It has a real-world application with clear stakeholder(s).\n",
        "*   You can answer the question using a machine learning model.\n",
        "*   You know (or have a pretty good idea) which machine learning model will be appropriate for your research question.\n",
        "*   You have a pretty good idea how to find the data that will answer your question (more on that later).\n",
        "*   You don't know the answer in advance. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yuxln0sDSaTI"
      },
      "source": [
        "**Step 2 Answer**\n",
        "\n",
        "I'm goint to focus on Health and Humanitarian questions.\n",
        "\n",
        "1. How can I use machine learning to diagnose the problem?\n",
        "\n",
        "2. How can I use machine learning to see if the data is biased?\n",
        "\n",
        "3. How can I use machine learning to test that certain factors play a role in diagnosing?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwjFEfxKSvUD"
      },
      "source": [
        "**Step 3** \n",
        "\n",
        "Rank your three potential research questions from Step 2 in order from one to three with one being your top choice and two and three being backup choices.  \n",
        "\n",
        "When ranking your research questions, think both about what interests you the most and what will be practical.  How well-defined is each research question?  How difficult will it be to find data to answer that question?  How difficult will it be to wrangle the data?  How confident do you feel about selecting an ML model to answer the research question?\n",
        "\n",
        "This is a great time to involve your instructor, who can provide guidance on revising your ideas in Step 2 and identifying your top and backup research questions. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbIdifQkUdVI"
      },
      "source": [
        "**Step 3 Answer**\n",
        "\n",
        "First Choice: How can I use machine learning to diagnose the problem?\n",
        "\n",
        "Backup Choices: How can I use machine learning to see if the data is biased? How can I use machine learning to test that certain factors play a role in diagnosing?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3x-aZs05UlJE"
      },
      "source": [
        "**My Milestone Project 3 Research Question Is:**\n",
        "\n",
        "How can I use machine learning to diagnose the problem?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0wz2-4iUytl"
      },
      "source": [
        "### Task 2: Select a Data Set \n",
        "\n",
        "Once you have a research question, you need to find a publically available data set that will allow you to answer it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdH_T0n4VNgT"
      },
      "source": [
        "\n",
        "There are lots of potential sources.  A few that are particularly useful are:\n",
        "\n",
        "Awesome public data sets: https://github.com/awesomedata/awesome-public-datasets\n",
        "\n",
        "Kaggle: https://www.kaggle.com/datasets\n",
        "\n",
        "UC Irvine Machine Learning: https://archive.ics.uci.edu/ml/datasets.php\n",
        "\n",
        "Definitely Google around for more data sources and ask your peers and instructor!\n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Vf4NTGMVhqM"
      },
      "source": [
        "**Step 1** \n",
        "\n",
        "Find at least one data set that you can use to answer your research question from Task 1.  \n",
        "\n",
        "Your data set should:\n",
        "* Be at least 100 records long.  You'll need a lot more records if you want to use a neural network.  \n",
        "* Be publicly available on the Internet. Don't collect your own data.  Don’t use data that can’t be attributed to a reputable source.\n",
        "* Have at least four features (remember that, when modeling text data, each word is a feature).\n",
        "\n",
        "This is another good opportunity to check in with your instructor and make sure you are on the right track.  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_DfahMdW4Rt"
      },
      "source": [
        "**Step 1 Answer**\n",
        "\n",
        "I am going to use a data set of average % of children aged 0-59 months in different countries who are severe wasting, wasting, overweight, stunting, and underweight. \n",
        "\n",
        "https://www.kaggle.com/datasets/ruchi798/malnutrition-across-the-globe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvo6xPBE5_Q8"
      },
      "source": [
        "**Step 2** \n",
        "\n",
        "Refine your research question so it applies to your specific data set.  \n",
        "\n",
        "For example, if your broad research question was \"How can I use machine learning to group customers by what they buy?\" and you select a data set that contains Target holiday shopping orders, your refined research question might be something like, \"Can I group Target customers by their holiday shopping orders?\"\n",
        "\n",
        "**At this point, it is possible that you will discover that you can't find a data set and research question that work well together.  Work with your instructor to either modify your current question or select one of your backup research questions above. To complete this task successfully, you will need to have selected a research question AND have a data set that can be used to answer it.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kk-rG1e17GW0"
      },
      "source": [
        "**Step 2 Answer**\n",
        "\n",
        "Original question: how can I use machine learning to help diagnose the problem?\n",
        "\n",
        "Refined question: How can I use machine learning to use the average of different malnutrition in children to predict the likihood of growth problems?\n",
        "\n",
        "a new source of information about malnutrition in children: https://globalnutritionreport.org/reports/global-nutrition-report-2018/burden-malnutrition/#note-b2a67844-2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2ld_oYpXTlS"
      },
      "source": [
        "### Task 3: Conduct Exploratory Data Analysis \n",
        "\n",
        "The purpose of exploratory data analysis at the project planning stage is to make sure that your data will answer your research question. It is possible to do everything correctly during this step and still hit a roadblock when you actually run your ML model, but it’s much less likely.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5xspQ0_XyH2"
      },
      "source": [
        "**Step 1** \n",
        "\n",
        "Determine the type(s) of machine learning model(s) you will use to answer your research question.  There might be only one type of model that will work, or you might have a number of models to choose from."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufMSg0vqYTY4"
      },
      "source": [
        "**Step 1 Answer**\n",
        "\n",
        "I will need to use a classififcation model to answer this question. i will break up factors of malnutrition up into categories that will help me define from overweight to severe wasting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPokiwSFYZbN"
      },
      "source": [
        "**Step 2** \n",
        "\n",
        "Are there any requirements your data must meet to use the ML model(s) you listed in Step 1?  For example, if you plan to use a logistic regression model, you must have a categorical target.  If you wish to use natural language processing, you'll need a large amount of text data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1OF8YFSZMIU"
      },
      "source": [
        "**Step 2 Answer**\n",
        "\n",
        "Yes, I will be using a categorical target."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLbjR-PyZVwg"
      },
      "source": [
        "**Step 3** \n",
        "\n",
        "Using visualizations or summary data, show that the requirements you listed in Step 2 are met by your data.  Feel free to add code blocks as necessary.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edfSQnaxcMR2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "530ffd0c-ba72-40db-cc21-40ab15054133"
      },
      "source": [
        "#Step 3 Answer:\n",
        "\n",
        "from google.colab import files\n",
        "Malnutrition = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3ee74bf7-054d-466f-991a-e8490c3fc2dd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3ee74bf7-054d-466f-991a-e8490c3fc2dd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving country-wise-average.csv to country-wise-average.csv\n",
            "Saving malnutrition-estimates.csv to malnutrition-estimates.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "malnutrition = pd.read_csv('malnutrition-estimates.csv')\n",
        "countrywise = pd.read_csv('country-wise-average.csv')\n",
        "\n",
        "malnutrition.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "id": "fCt8Estf4R_Q",
        "outputId": "a59c7b7b-2c50-4183-8058-02becf4981d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0 ISO code      Country Survey Year  Year  Income Classification  \\\n",
              "0           0      AFG  AFGHANISTAN        1997  1997                      0   \n",
              "1           1      AFG  AFGHANISTAN        2004  2004                      0   \n",
              "2           2      AFG  AFGHANISTAN        2013  2013                      0   \n",
              "3           3      AFG  AFGHANISTAN        2018  2018                      0   \n",
              "4           4      ALB      ALBANIA     1996-98  1997                      2   \n",
              "\n",
              "   LDC  LIFD  LLDC or SID2 Survey Sample (N)  Severe Wasting  Wasting  \\\n",
              "0  1.0   1.0           1.0             4,846             NaN     18.2   \n",
              "1  1.0   1.0           1.0               946             3.5      8.6   \n",
              "2  1.0   1.0           1.0         44,26,469             4.0      9.5   \n",
              "3  1.0   1.0           1.0               NaN             1.6      5.1   \n",
              "4  0.0   0.0           0.0             7,642             NaN      8.1   \n",
              "\n",
              "   Overweight  Stunting  Underweight                Notes  \\\n",
              "0         6.5      53.2         44.9  Converted estimates   \n",
              "1         4.6      59.3         32.9                  NaN   \n",
              "2         5.3      40.4         24.6                  NaN   \n",
              "3         4.1      38.2         19.1                  NaN   \n",
              "4         9.5      20.4          7.1  Converted estimates   \n",
              "\n",
              "                                       Report Author  \\\n",
              "0                                 CIET International   \n",
              "1  Ministry of Public Health (Afghanistan), UNICE...   \n",
              "2  Ministry of Public Health, UNICEF and the Aga ...   \n",
              "3                       KIT Royal Tropical Institute   \n",
              "4  Institute of Public Health, Food and Nutrition...   \n",
              "\n",
              "                                              Source Short Source  \\\n",
              "0  Afghanistan 1997 multiple indicator baseline (...         MICS   \n",
              "1  Summary report of the national nutrition surve...          NNS   \n",
              "2        Afghanistan National Nutrition Survey 2013.        SMART   \n",
              "3                     Afghanistan Health Survey 2018        Other   \n",
              "4  National study on nutrition in Albania. Instit...        Other   \n",
              "\n",
              "   U5 Population ('000s)  \n",
              "0               3838.877  \n",
              "1               4789.353  \n",
              "2               5444.573  \n",
              "3               5601.443  \n",
              "4                309.225  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5f79c0fb-16b4-429f-835a-05a2942e15c5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>ISO code</th>\n",
              "      <th>Country</th>\n",
              "      <th>Survey Year</th>\n",
              "      <th>Year</th>\n",
              "      <th>Income Classification</th>\n",
              "      <th>LDC</th>\n",
              "      <th>LIFD</th>\n",
              "      <th>LLDC or SID2</th>\n",
              "      <th>Survey Sample (N)</th>\n",
              "      <th>Severe Wasting</th>\n",
              "      <th>Wasting</th>\n",
              "      <th>Overweight</th>\n",
              "      <th>Stunting</th>\n",
              "      <th>Underweight</th>\n",
              "      <th>Notes</th>\n",
              "      <th>Report Author</th>\n",
              "      <th>Source</th>\n",
              "      <th>Short Source</th>\n",
              "      <th>U5 Population ('000s)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>AFG</td>\n",
              "      <td>AFGHANISTAN</td>\n",
              "      <td>1997</td>\n",
              "      <td>1997</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4,846</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18.2</td>\n",
              "      <td>6.5</td>\n",
              "      <td>53.2</td>\n",
              "      <td>44.9</td>\n",
              "      <td>Converted estimates</td>\n",
              "      <td>CIET International</td>\n",
              "      <td>Afghanistan 1997 multiple indicator baseline (...</td>\n",
              "      <td>MICS</td>\n",
              "      <td>3838.877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>AFG</td>\n",
              "      <td>AFGHANISTAN</td>\n",
              "      <td>2004</td>\n",
              "      <td>2004</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>946</td>\n",
              "      <td>3.5</td>\n",
              "      <td>8.6</td>\n",
              "      <td>4.6</td>\n",
              "      <td>59.3</td>\n",
              "      <td>32.9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Ministry of Public Health (Afghanistan), UNICE...</td>\n",
              "      <td>Summary report of the national nutrition surve...</td>\n",
              "      <td>NNS</td>\n",
              "      <td>4789.353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>AFG</td>\n",
              "      <td>AFGHANISTAN</td>\n",
              "      <td>2013</td>\n",
              "      <td>2013</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>44,26,469</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9.5</td>\n",
              "      <td>5.3</td>\n",
              "      <td>40.4</td>\n",
              "      <td>24.6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Ministry of Public Health, UNICEF and the Aga ...</td>\n",
              "      <td>Afghanistan National Nutrition Survey 2013.</td>\n",
              "      <td>SMART</td>\n",
              "      <td>5444.573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>AFG</td>\n",
              "      <td>AFGHANISTAN</td>\n",
              "      <td>2018</td>\n",
              "      <td>2018</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.6</td>\n",
              "      <td>5.1</td>\n",
              "      <td>4.1</td>\n",
              "      <td>38.2</td>\n",
              "      <td>19.1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>KIT Royal Tropical Institute</td>\n",
              "      <td>Afghanistan Health Survey 2018</td>\n",
              "      <td>Other</td>\n",
              "      <td>5601.443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>ALB</td>\n",
              "      <td>ALBANIA</td>\n",
              "      <td>1996-98</td>\n",
              "      <td>1997</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7,642</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.1</td>\n",
              "      <td>9.5</td>\n",
              "      <td>20.4</td>\n",
              "      <td>7.1</td>\n",
              "      <td>Converted estimates</td>\n",
              "      <td>Institute of Public Health, Food and Nutrition...</td>\n",
              "      <td>National study on nutrition in Albania. Instit...</td>\n",
              "      <td>Other</td>\n",
              "      <td>309.225</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f79c0fb-16b4-429f-835a-05a2942e15c5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5f79c0fb-16b4-429f-835a-05a2942e15c5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5f79c0fb-16b4-429f-835a-05a2942e15c5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "countrywise.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "CI96e9cL4ajy",
        "outputId": "d31e2203-25ef-402d-9b96-a86826b21b38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Country  Income Classification  Severe Wasting    Wasting  Overweight  \\\n",
              "0  AFGHANISTAN                    0.0        3.033333  10.350000    5.125000   \n",
              "1      ALBANIA                    2.0        4.075000   7.760000   20.800000   \n",
              "2      ALGERIA                    2.0        2.733333   5.942857   12.833333   \n",
              "3       ANGOLA                    1.0        2.400000   6.933333    2.550000   \n",
              "4    ARGENTINA                    2.0        0.200000   2.150000   11.125000   \n",
              "\n",
              "    Stunting  Underweight  U5 Population ('000s)  \n",
              "0  47.775000    30.375000            4918.561500  \n",
              "1  24.160000     7.700000             232.859800  \n",
              "2  19.571429     7.342857            3565.213143  \n",
              "3  42.633333    23.600000            3980.054000  \n",
              "4  10.025000     2.600000            3613.651750  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5a81d256-a59f-4bef-a12d-3f9425631a6d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Country</th>\n",
              "      <th>Income Classification</th>\n",
              "      <th>Severe Wasting</th>\n",
              "      <th>Wasting</th>\n",
              "      <th>Overweight</th>\n",
              "      <th>Stunting</th>\n",
              "      <th>Underweight</th>\n",
              "      <th>U5 Population ('000s)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AFGHANISTAN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.033333</td>\n",
              "      <td>10.350000</td>\n",
              "      <td>5.125000</td>\n",
              "      <td>47.775000</td>\n",
              "      <td>30.375000</td>\n",
              "      <td>4918.561500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ALBANIA</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.075000</td>\n",
              "      <td>7.760000</td>\n",
              "      <td>20.800000</td>\n",
              "      <td>24.160000</td>\n",
              "      <td>7.700000</td>\n",
              "      <td>232.859800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ALGERIA</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.733333</td>\n",
              "      <td>5.942857</td>\n",
              "      <td>12.833333</td>\n",
              "      <td>19.571429</td>\n",
              "      <td>7.342857</td>\n",
              "      <td>3565.213143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ANGOLA</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.400000</td>\n",
              "      <td>6.933333</td>\n",
              "      <td>2.550000</td>\n",
              "      <td>42.633333</td>\n",
              "      <td>23.600000</td>\n",
              "      <td>3980.054000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ARGENTINA</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>2.150000</td>\n",
              "      <td>11.125000</td>\n",
              "      <td>10.025000</td>\n",
              "      <td>2.600000</td>\n",
              "      <td>3613.651750</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5a81d256-a59f-4bef-a12d-3f9425631a6d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5a81d256-a59f-4bef-a12d-3f9425631a6d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5a81d256-a59f-4bef-a12d-3f9425631a6d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIXTz2t7VatW"
      },
      "source": [
        "**Step 4**\n",
        "\n",
        "Explore your data to determine what kind of data cleaning or wrangling will be necessary before you run your ML model. \n",
        "\n",
        "Here are some questions to consider:\n",
        "* How many observations does your data set have?\n",
        "* How many features does your data set have?\n",
        "* Does your data have any missing values?\n",
        "* If your data has missing values, will you drop the records or impute the missing data?  What will your imputation strategy be? \n",
        "* Does your data have any outliers or unusual values?  If so, how will you handle them? \n",
        "* Will you need to do any feature engineering or drop any features from your data?\n",
        "* Will you need to encode any categorical data or standardize or normalize quantitative features?  \n",
        "* Will you need to split your data into traning and testing sets?\n",
        "* Will you need to do any preprocessing of text data?\n",
        "\n",
        "If you aren’t sure how to answer any of these questions, your instructor can give you guidance and suggestions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBZmex_8cVvd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c814317d-a98a-420b-d8c4-ab33c01f5be7"
      },
      "source": [
        "#Step 4 Answer: for countrywise data set\n",
        "\n",
        "#Determining the number of obersvations and features \n",
        "print('The number of features in my country wise data is', countrywise.shape[1])\n",
        "print('The number of obervations in my country wise data is', countrywise.shape[0]) #counting the rows to make sure I have over 100 \n",
        "\n",
        "#checking for missing values \n",
        "print('The number of missing values in my country wise data is', countrywise.isnull().sum().sum()) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of features in my country wise data is 8\n",
            "The number of obervations in my country wise data is 152\n",
            "The number of missing values in my country wise data is 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "countrywise.dtypes # checking the data types"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8WaCRnq6rUf",
        "outputId": "76c51730-0faa-4008-f292-ea9b3993362f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Country                   object\n",
              "Income Classification    float64\n",
              "Severe Wasting           float64\n",
              "Wasting                  float64\n",
              "Overweight               float64\n",
              "Stunting                 float64\n",
              "Underweight              float64\n",
              "U5 Population ('000s)    float64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(countrywise.isnull().sum()) #printing out the nulls to find the colum with the least amount of nulls with the factors of weight over age."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPPE32XO8qbz",
        "outputId": "feebb876-8ddb-48fd-b150-3a8295e33880"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Country                   0\n",
            "Income Classification     0\n",
            "Severe Wasting           12\n",
            "Wasting                   2\n",
            "Overweight                3\n",
            "Stunting                  1\n",
            "Underweight               2\n",
            "U5 Population ('000s)     0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 4 Answer: for malnutrition data set\n",
        "\n",
        "#Determining the number of obersvations and features \n",
        "print('The number of features in my malnutrition data is', malnutrition.shape[1])\n",
        "print('The number of obervations in my malnutrition data is', malnutrition.shape[0]) #counting the rows to make sure I have over 100 \n",
        "\n",
        "#checking for missing values \n",
        "print('The number of missing values in my malnutririon data is', malnutrition.isnull().sum().sum()) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iV597hKD6wI9",
        "outputId": "de953bd3-8a78-4287-c998-38c3e85cb884"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of features in my malnutrition data is 20\n",
            "The number of obervations in my malnutrition data is 924\n",
            "The number of missing values in my malnutririon data is 1130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "malnutrition.dtypes # checking the data types"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1Ij8RwZ69AX",
        "outputId": "df06d7e2-3bd4-4401-a649-31b7de1a12f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0                 int64\n",
              "ISO code                  object\n",
              "Country                   object\n",
              "Survey Year               object\n",
              "Year                       int64\n",
              "Income Classification      int64\n",
              "LDC                      float64\n",
              "LIFD                     float64\n",
              "LLDC or SID2             float64\n",
              "Survey Sample (N)         object\n",
              "Severe Wasting           float64\n",
              "Wasting                  float64\n",
              "Overweight               float64\n",
              "Stunting                 float64\n",
              "Underweight              float64\n",
              "Notes                     object\n",
              "Report Author             object\n",
              "Source                    object\n",
              "Short Source              object\n",
              "U5 Population ('000s)    float64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(malnutrition.isnull().sum()) #printing out the nulls to find the colum with the least amount of nulls with the factors of weight over age."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaytT06m7cz-",
        "outputId": "23342341-0c87-4f49-8fab-24c3609a1638"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unnamed: 0                 0\n",
            "ISO code                   0\n",
            "Country                    0\n",
            "Survey Year                0\n",
            "Year                       0\n",
            "Income Classification      0\n",
            "LDC                        0\n",
            "LIFD                       0\n",
            "LLDC or SID2               0\n",
            "Survey Sample (N)         63\n",
            "Severe Wasting           228\n",
            "Wasting                   47\n",
            "Overweight               136\n",
            "Stunting                  37\n",
            "Underweight               22\n",
            "Notes                    597\n",
            "Report Author              0\n",
            "Source                     0\n",
            "Short Source               0\n",
            "U5 Population ('000s)      0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6kHJMnKbDra"
      },
      "source": [
        "**Step 4 Answer**\n",
        "\n",
        "My data has 1076 total observations and 28 features. There is a lot of missing data in the second set (primarily in the notes and severe wasting). In total there is 1150 total missing values. \n",
        "\n",
        "I will need to figure out a way to impute or drop the missing values. and then I will need to do quite a bit of feature engineering. \n",
        "\n",
        "I will likely need to standardize/normalize the data.\n",
        "\n",
        "Because my target variable is currently to give the precentage of each type of malnutrition per country I will need to categorize them into two categoies. based on reading about this data i will categorize below a certain percetage for healthy population as 0, and if they are above the percentage then I will add them to at risk population as 1. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJFE-Gk1dHlG"
      },
      "source": [
        "**At this point, it is possible that you will discover that you can't answer your research question with your data set.  Work with your instructor to either modify your research question, select a backup research question, or select a new data set. To complete this task successfully, you will need to have selected a research question, have a data set that can be used to answer it, AND have performed EDA.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhyI1UgEcxOC"
      },
      "source": [
        "### Task 4: Develop a Project Plan \n",
        "\n",
        "Now you are ready to plan out everything that will be in your final project slide deck.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6A0y3Q7eUCo"
      },
      "source": [
        "**Step 1** \n",
        "\n",
        "Write about one paragraph of background to give your audience some context for your research question.  What motivated you to ask this specific research question?  What is the real world application?  Think about your stakeholder(s) and what that person would want to know about the topic before you got started."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwCPbC0We_fE"
      },
      "source": [
        "**Step 1 Answer**\n",
        "\n",
        "\"As in previous years, the 2018 Global Nutrition Report finds again that the problem of malnutrition remains severe: the world is not on track to achieve the targets it has set itself. Malnutrition in all its forms remains unacceptably high across all regions of the world.\" it seems that 2000 is our baseline in stunting "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEwt_DrIedv6"
      },
      "source": [
        "**Step 2** \n",
        "\n",
        "Write one or two paragraphs describing your data set.  What was the source of the data?   Why did you choose to use this particular data set?  Did you experience any challenges with accessing or loading the data?  Describe any data wrangling you need to do to run your ML model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6aD8mXffCBd"
      },
      "source": [
        "**Step 2 Answer**\n",
        "\n",
        "The source of my data is a 2019 study done by Unicef. You can look at their most recent study from 2022 (https://data.unicef.org/topic/nutrition/malnutrition/) to see a more detailed description. \n",
        "\n",
        "I chose this data set because it was labeled as a highly usable set and it seemed interesting to me. I did not have any challenges loading the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_1IYpwRev5M"
      },
      "source": [
        "**Step 3**\n",
        "\n",
        "Write one paragraph describing the model or models you plan to use.  Why did you pick this model or models?  How will they answer your research question?  What metrics will you use to evaluate the model performance?  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6_lhy2wfEdQ"
      },
      "source": [
        "**Step 3 Answer**\n",
        "\n",
        "I plan on using a categorical model like logistic regression or Gradientboost.\n",
        "\n",
        "I like using gradient boost because it is robust classifier that can preform on any data set. It is one of the most successful ML techniques and is widely used in practice across a variety of use cases. I will use the results from 10-fold cross validation scores to evaluate the models preformance. If I can get the model to accuratley identify at risk countries based off of average then I can conclude to adding this to the future testing of these data sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTynDQ5Xe3Ee"
      },
      "source": [
        "**Step 4**\n",
        "\n",
        "Think about your intended audience.  How will you communicate your results to your stakeholders?  What data storytelling techniques will you use in your presentation to engage your audience?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiK51IpWfGtV"
      },
      "source": [
        "**Step 4 Answer**\n",
        "\n",
        "I will be coveying this project to both technical and non technical people. I will use graphs and pictures for the non technical audience in my EDA. Then I will use comparison for the non technical people in the ML. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Task 5: Data Wrangling\n",
        "\n",
        "Use the following code block (feel free to add more) to do any data wrangling.  It may be helpful to refer to the questions you answered previously in the Exploratory Data Analysis section.  For reference, they are:\n",
        "\n",
        "Here are some questions to consider:\n",
        "\n",
        "* How many observations does your data set have?\n",
        "* How many features does your data set have?\n",
        "* Does your data have any missing values?\n",
        "* If your data has missing values, will you drop the records or impute the * missing data? What will your imputation strategy be?\n",
        "* Does your data have any outliers or unusual values? If so, how will you handle them?\n",
        "* Will you need to do any feature engineering or drop any features from your data?\n",
        "* Will you need to encode any categorical data or standardize or normalize quantitative features?\n",
        "* Will you need to split your data into traning and testing sets?\n",
        "* Will you need to do any pre-processing of text data?"
      ],
      "metadata": {
        "id": "PRpKLHkDnKGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 5 - Data Wrangling - Use this code block to do any data wrangling.\n",
        "# Make sure to clearly comment your code.\n",
        "\n",
        "#Import libraries and packages \n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "from sklearn import tree, ensemble\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso, RidgeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
        "from sklearn.svm import SVC, SVR\n",
        "from sklearn.naive_bayes import MultinomialNB, CategoricalNB\n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz, DecisionTreeRegressor\t\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.ensemble import AdaBoostRegressor, AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler,\tMaxAbsScaler\n",
        "from sklearn.model_selection import cross_val_score, train_test_split, \tGridSearchCV\n",
        "from sklearn.metrics import roc_curve, auc, confusion_matrix, precision_score, recall_score\n",
        "# explicitly require this experimental feature\n",
        "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
        "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "YQMcpQNBnFJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For countrywise data set\n",
        "\n",
        "#Determining the number of obersvations and features \n",
        "print('The number of features in my country wise data is', countrywise.shape[1])\n",
        "print('The number of obervations in my country wise data is', countrywise.shape[0]) #counting the rows to make sure I have over 100 \n",
        "\n",
        "#checking for missing values \n",
        "print('The number of missing values in my country wise data is', countrywise.isnull().sum().sum()) "
      ],
      "metadata": {
        "id": "5uxXI0OgYvjm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "358a249e-38ef-4c95-8aba-a804705bde60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of features in my country wise data is 8\n",
            "The number of obervations in my country wise data is 152\n",
            "The number of missing values in my country wise data is 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#For malnutrition data set\n",
        "\n",
        "#Determining the number of obersvations and features \n",
        "print('The number of features in my malnutrition data is', malnutrition.shape[1])\n",
        "print('The number of obervations in my malnutrition data is', malnutrition.shape[0]) #counting the rows to make sure I have over 100 \n",
        "\n",
        "#checking for missing values \n",
        "print('The number of missing values in my malnutririon data is', malnutrition.isnull().sum().sum()) "
      ],
      "metadata": {
        "id": "6qu5Yu_ZY2Km",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95c0e206-3b27-40dd-ce59-47315206b381"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of features in my malnutrition data is 20\n",
            "The number of obervations in my malnutrition data is 924\n",
            "The number of missing values in my malnutririon data is 1130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "malnutrition['Wasting'] = malnutrition['Wasting'].round().astype('Int64')\n",
        "malnutrition['Severe Wasting'] = malnutrition['Severe Wasting'].round().astype('Int64')\n",
        "malnutrition['Overweight'] = malnutrition['Overweight'].round().astype('Int64')\n",
        "malnutrition['Stunting'] = malnutrition['Stunting'].round().astype('Int64')\n",
        "malnutrition['Underweight'] = malnutrition['Underweight'].round().astype('Int64')"
      ],
      "metadata": {
        "id": "UoxC2U2RyAis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 5 Continued\n",
        "\n",
        "# used loc function to change data in the colum to categorical. knew wasting was important to the data set because the higher wasting the higher sever wasting. \n",
        "\n",
        "# Wasting Categories \n",
        "#higest value is 20.7\n",
        "malnutrition.loc[(malnutrition['Wasting'] >= 0.0) & (malnutrition['Wasting'] < 3.0), 'Wasting present'] = 0\n",
        "malnutrition.loc[(malnutrition['Wasting'] >= 3.0) & (malnutrition['Wasting'] < 6.0), 'Wasting present'] = 1 \n",
        "malnutrition.loc[(malnutrition['Wasting'] >= 6.0) & (malnutrition['Wasting'] < 9.0), 'Wasting present'] = 2 \n",
        "malnutrition.loc[(malnutrition['Wasting'] >= 9.0) & (malnutrition['Wasting'] < 12.0), 'Wasting present'] = 3\n",
        "malnutrition.loc[(malnutrition['Wasting'] >= 12.0) & (malnutrition['Wasting'] < 15.0), 'Wasting present'] = 4\n",
        "malnutrition.loc[(malnutrition['Wasting'] >= 15.0) & (malnutrition['Wasting'] < 18.0), 'Wasting present'] = 5\n",
        "malnutrition.loc[(malnutrition['Wasting'] >= 18.0) & (malnutrition['Wasting'] <= 21.0), 'Wasting present'] = 6  \n",
        "\n",
        "# Severe Wasting Categories \n",
        "#highest value is 6.8\n",
        "malnutrition.loc[(malnutrition['Severe Wasting'] >= 0.0) & (malnutrition['Severe Wasting'] < 2.0), 'SWasting present'] = 0\n",
        "malnutrition.loc[(malnutrition['Severe Wasting'] >= 2.0) & (malnutrition['Severe Wasting'] < 4.0), 'SWasting present'] = 1\n",
        "malnutrition.loc[(malnutrition['Severe Wasting'] >= 4.0) & (malnutrition['Severe Wasting'] < 6.0), 'SWasting present'] = 2\n",
        "malnutrition.loc[(malnutrition['Severe Wasting'] >= 6.0) & (malnutrition['Severe Wasting'] < 8.0), 'SWasting present'] = 3\n",
        "\n",
        "# Overweight Categories \n",
        "#higest value is 30.1\n",
        "malnutrition.loc[(malnutrition['Overweight'] >= 0.0) & (malnutrition['Overweight'] < 5.0), 'Overweight present'] = 0\n",
        "malnutrition.loc[(malnutrition['Overweight'] >= 5.0) & (malnutrition['Overweight'] < 10.0), 'Overweight present'] = 1\n",
        "malnutrition.loc[(malnutrition['Overweight'] >= 10.0) & (malnutrition['Overweight'] < 15.0), 'Overweight present'] = 2\n",
        "malnutrition.loc[(malnutrition['Overweight'] >= 15.0) & (malnutrition['Overweight'] < 20.0), 'Overweight present'] = 3\n",
        "malnutrition.loc[(malnutrition['Overweight'] >= 20.0) & (malnutrition['Overweight'] < 25.0), 'Overweight present'] = 4\n",
        "malnutrition.loc[(malnutrition['Overweight'] >= 25.0) & (malnutrition['Overweight'] <= 30.0), 'Overweight present'] = 5\n",
        "\n",
        "# Stunting Categories \n",
        "# highest value is 73.6\n",
        "malnutrition.loc[(malnutrition['Stunting'] >= 0.0) & (malnutrition['Stunting'] < 18.0), 'Stunting present'] = 0\n",
        "malnutrition.loc[(malnutrition['Stunting'] >= 18.0) & (malnutrition['Stunting'] < 37.0), 'Stunting present'] = 1\n",
        "malnutrition.loc[(malnutrition['Stunting'] >= 37.0) & (malnutrition['Stunting'] < 55.0), 'Stunting present'] = 2\n",
        "malnutrition.loc[(malnutrition['Stunting'] >= 55.0) & (malnutrition['Stunting'] < 74.0), 'Stunting present'] = 3\n",
        "\n",
        "# Underweight Categories \n",
        "# highest value is 66.8\n",
        "malnutrition.loc[(malnutrition['Underweight'] >= 0.0) & (malnutrition['Underweight'] < 1.0), 'Underweight present'] = 0\n",
        "malnutrition.loc[(malnutrition['Underweight'] >= 1.0) & (malnutrition['Underweight'] < 10.0), 'Underweight present'] = 1\n",
        "malnutrition.loc[(malnutrition['Underweight'] >= 10.0) & (malnutrition['Underweight'] < 20.0), 'Underweight present'] = 2\n",
        "malnutrition.loc[(malnutrition['Underweight'] >= 20.0) & (malnutrition['Underweight'] < 30.0), 'Underweight present'] = 3\n",
        "malnutrition.loc[(malnutrition['Underweight'] >= 40.0) & (malnutrition['Underweight'] < 50.0), 'Underweight present'] = 4\n",
        "malnutrition.loc[(malnutrition['Underweight'] >= 50.0) & (malnutrition['Underweight'] < 70.0), 'Underweight present'] = 5\n",
        "\n"
      ],
      "metadata": {
        "id": "d8lpSdFIZBKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Task 6: Modeling\n",
        "\n",
        "Use the following code block to build your ML model.  "
      ],
      "metadata": {
        "id": "FVyXtpPhnxMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 6 - Modeling - Use this code block to build your ML model.\n",
        "# Make sure to clearly comment your code."
      ],
      "metadata": {
        "id": "W8pVuG8OowqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split the data into the target variable and the feature of interest\n",
        "X = malnutrition.drop(columns=[\"Severe Wasting\",\"Wasting\", \"Overweight\", \"Stunting\", \"Underweight\", \"Notes\", \"Report Author\", \"Source\", \"Short Source\", \"U5 Population ('000s)\",\"ISO code\", \"Country\", \"Survey Year\", \"Year\", \"LLDC or SID2\", \"Survey Sample (N)\", \"LDC\",\"LIFD\"], axis=1, errors=\"ignore\") #dropping colums that dont hold numeric data and columns that dont make sense to keep.\n",
        "y = malnutrition[[\"LIFD\"]]\n",
        "y1 = malnutrition[[\"LDC\"]]\n",
        "\n",
        "#Split the data into a training dataset and a test dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "X_train, X_test, y1_train, y1_test = train_test_split(X, y1, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "jC_95KrX2M5N"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build a pipeline that will impute and standardize the data and fit a logistic regression model\n",
        "log_pipe = Pipeline([\n",
        "    ('ite_imp', IterativeImputer(missing_values=np.nan)), # getting rid of missing values \n",
        "    ('scaler', StandardScaler()), # standarizing features \n",
        "    ('log_reg', LogisticRegression(random_state=0))])\n",
        "\n",
        "#Fitting the pipline to training set \n",
        "log_pipe.fit(X_train, y_train)\n",
        "\n",
        "#vs the second model\n",
        "\n",
        "log_pipe1 = Pipeline([\n",
        "    ('ite_imp', IterativeImputer(missing_values=np.nan)), # getting rid of missing values \n",
        "    ('scaler', StandardScaler()), # standarizing features \n",
        "    ('log_reg', LogisticRegression(random_state=0))])\n",
        "\n",
        "#Fitting the pipline to training set \n",
        "log_pipe1.fit(X_train, y1_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYn2mMlh33Q7",
        "outputId": "fedc76d9-7008-49a2-8946-00db90f8cc5d"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('ite_imp', IterativeImputer()), ('scaler', StandardScaler()),\n",
              "                ('log_reg', LogisticRegression(random_state=0))])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Build and Evaluate a Pipeline That Will Impute and Standardize the Data and Fit the GradientBoost Boosting Classifier with the Default Hyperparameters\n",
        "GradientBoost = Pipeline([\n",
        "    ('ite_imp', IterativeImputer(missing_values=np.nan)), # getting rid of missing values \n",
        "    ('gradientboost', GradientBoostingClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "#Fitting the pipline to training set \n",
        "GradientBoost.fit(X_train, y_train)\n",
        "\n",
        "#vs the second model\n",
        "\n",
        "GradientBoost1 = Pipeline([\n",
        "    ('ite_imp', IterativeImputer(missing_values=np.nan)), # getting rid of missing values \n",
        "    ('gradientboost', GradientBoostingClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "#Fitting the pipline to training set \n",
        "GradientBoost1.fit(X_train, y1_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Cv1OoW34ctm",
        "outputId": "e03de786-90c2-4ef7-dbf9-1569b5942456"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('ite_imp', IterativeImputer()),\n",
              "                ('gradientboost', GradientBoostingClassifier(random_state=42))])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Task 7: Evaluation\n",
        "\n",
        "Use the following code block to evaluate your ML model.  "
      ],
      "metadata": {
        "id": "nqpRwrQPo4WK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 7 - Evaluation - Use this code block to evaluate your ML model.\n",
        "# Make sure to clearly comment your code."
      ],
      "metadata": {
        "id": "sqq4AwbppBs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate Logistic pipeline using 10-fold cross-validation\n",
        "LIFDscores = cross_val_score(log_pipe, X_train, y_train, cv=10) # Using cross-validation to calulate the model \n",
        "print('The mean 10-fold CV accuracy for logistic regression using LIFD is', LIFDscores.mean())\n",
        "print('The SD 10-fold CV accuracy for logistic regression usinf LIFD is', LIFDscores.std())\n",
        "\n",
        "#vs \n",
        "\n",
        "LDCscores = cross_val_score(log_pipe1, X_train, y1_train, cv=10) # Using cross-validation to calulate the model \n",
        "print('The mean 10-fold CV accuracy for logistic regression using LDC is', LDCscores.mean())\n",
        "print('The SD 10-fold CV accuracy for logistic regression usinf LDC is', LDCscores.std())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2xxKi4C4jtm",
        "outputId": "b9919332-68a2-4c94-ead5-5822b8240c76"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The mean 10-fold CV accuracy for logistic regression using LIFD is 0.8642857142857142\n",
            "The SD 10-fold CV accuracy for logistic regression usinf LIFD is 0.042183344119811596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The mean 10-fold CV accuracy for logistic regression using LDC is 0.8615113871635611\n",
            "The SD 10-fold CV accuracy for logistic regression usinf LDC is 0.029602346619267316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate Gradient boost pipeline using 10-fold cross-validation\n",
        "GBscoresLIFD = cross_val_score(GradientBoost, X_train, y_train, cv=10) # Using cross-validation to calulate the model \n",
        "print('The mean 10-fold CV accuracy for Gradientboost using LIFD is', GBscoresLIFD.mean())\n",
        "print('The SD 10-fold CV accuracy for Gradientboost using LIFD is', GBscoresLIFD.std())\n",
        "\n",
        "#vs\n",
        "\n",
        "GBscoresLDC = cross_val_score(GradientBoost1, X_train, y1_train, cv=10) # Using cross-validation to calulate the model \n",
        "print('The mean 10-fold CV accuracy for Gradientboost using LDC is', GBscoresLDC.mean())\n",
        "print('The SD 10-fold CV accuracy for Gradientboost using LDC is', GBscoresLDC.std())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6tB_k2v4neH",
        "outputId": "a857f741-87d5-4bef-f11e-bd569db6ca80"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The mean 10-fold CV accuracy for Gradientboost using LIFD is 0.963913043478261\n",
            "The SD 10-fold CV accuracy for Gradientboost using LIFD is 0.020701459479482855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The mean 10-fold CV accuracy for Gradientboost using LDC is 0.9768737060041408\n",
            "The SD 10-fold CV accuracy for Gradientboost using LDC is 0.01855702024568189\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The Logistic score using LIFD is\", log_pipe.score(X_test, y_test))\n",
        "print(\"The Logistic score using LDC is\", log_pipe1.score(X_test, y1_test))\n",
        "print(\"The GradientBoost score uisng LIFD is\", GradientBoost.score(X_test, y_test))\n",
        "print(\"The GradientBoost score uisng LDC is\", GradientBoost1.score(X_test, y1_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0ZOkYWS4s-q",
        "outputId": "86890591-889e-4a83-f319-36c5100f75d9"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Logistic score using LIFD is 0.8571428571428571\n",
            "The Logistic score using LDC is 0.8701298701298701\n",
            "The GradientBoost score uisng LIFD is 0.9393939393939394\n",
            "The GradientBoost score uisng LDC is 0.935064935064935\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LDC is averging out a little higher than LIFD but they are almost interchangable."
      ],
      "metadata": {
        "id": "3QTfNJo5KCED"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Task 8: Results\n",
        "\n",
        "Use the following text block to summarize your results.  How will you communicate the answer to your research question to stakeholders? "
      ],
      "metadata": {
        "id": "28NBPyS3pJKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 8 Answer**\n",
        "\n",
        "Based on the results with gradient boost we can positivly predict risk of malnutrition with training the model to use LIFD (low income food deficient) or LDC (least developed countries) number against other categorical data."
      ],
      "metadata": {
        "id": "NlGxokmYpWrj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nN23e0hUQyVe"
      },
      "source": [
        "#Part 2: Presentation \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Task 1: Slide Deck\n",
        "\n",
        "Create and present a slide deck to your classmates showing how you answered your research question.  You can find a Slide Template in the course materials or create your own.  The presentation should be about five minutes long."
      ],
      "metadata": {
        "id": "EgSqhfISBF1j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Task 2: Reflection\n",
        "\n",
        "Use the following text block to reflect on the project.  Did you run into anything that was particularly difficult?  What part(s) of the project did you enjoy most?  Did your results leave you with any new questions you'd investigate if you had more time?"
      ],
      "metadata": {
        "id": "uoX0vHCAp8id"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2 Answer** \n",
        "\n",
        "Overall I enjoyed this project. I enjoyed doing the data wrangling even when it got confusing. I liked that i was able to do this in a timely manner. If I had more time I think I would try linear regression models to predict the average for each country. "
      ],
      "metadata": {
        "id": "LB42k9KkqVU-"
      }
    }
  ]
}